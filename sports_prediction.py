# -*- coding: utf-8 -*-
"""Sports_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOlwX5mxqi7qgY-KehaSyIViG5U_U-Vo

## Loading the dataset
"""

import numpy as np  
import pandas as pd
players_df = pd.read_csv('/content/drive/MyDrive/players_22.csv')

from google.colab import drive
drive.mount('/content/drive')

"""## Exploring the Dataset"""

#Overall info on the dataset
players_df.info()

#columns of the dataset
players_df.columns

#Shape of the dataset
players_df.shape

# check for datatypes, some might require changing depending on what needs to be done.
players_df.dtypes

# View summary statistics
players_df.describe()

"""## Cleaning the Dataset"""

# Drop irrelevant columns
players_df.drop(['sofifa_id', 'player_url', 'short_name', 'long_name', 'dob', 'real_face', 'nation_jersey_number', 'nation_position'], axis=1, inplace=True)

# checking for missing values
players_df.isnull().any()

#lets handle the above missing values
col = []
for c in players_df.columns:
    missing_values=np.mean(players_df[c].isnull())* 100
    if missing_values > 60:
        print('{} - {}%'.format(c, round(missing_values)))
        col.append(c)

print("\n We need to drop these columns: \n \n", col)

#Dropping the columns with missing values
players_df.drop(columns=['club_loaned_from', 'nation_team_id', 'player_tags', 'goalkeeping_speed', 'nation_logo_url'], inplace=True)

# Drop all the missing values and NaN
players_df.dropna()

"""## Extract the feauture"""

# Extract preferred foot
players_df['preferred_foot'] = players_df['preferred_foot'].apply(lambda x: 1 if x == 'Right' else 0)

# Calculate overall potential
players_df['overall_potential'] = players_df['overall'] + players_df['potential']

"""## Feature Selection"""

# Calculate correlation coefficients
corr_matrix = players_df.corr()
corr_matrix['overall'].sort_values(ascending=False)

#Drop less correlated features
players_df.drop(columns=['goalkeeping_positioning','goalkeeping_reflexes','goalkeeping_diving',
                         'goalkeeping_handling','goalkeeping_kicking',
                         'preferred_foot','nationality_id','league_level','club_jersey_number','club_team_id'])

# Select top features
feature_subset = players_df[['age', 'potential', 'value_eur', 'wage_eur', 'international_reputation', 'overall_potential']]

"""## Model Training and measure the perfomance of the model"""

## creating a new df with only numerical dtypes
new_df = players_df[['potential', 'potential', 'value_eur', 'wage_eur', 
            'age',  'height_cm', 'weight_kg', 
            'pace',
          'shooting',
          'passing',
          'dribbling',
          'defending',
          'physic',
          'attacking_crossing',
          'attacking_finishing',
          'attacking_heading_accuracy',
          'attacking_short_passing',
          'attacking_volleys',
          'skill_dribbling',
          'skill_curve',
          'skill_fk_accuracy',
          'skill_long_passing',
          'skill_ball_control',
          'movement_acceleration',
          'movement_sprint_speed',
          'movement_agility',
          'movement_reactions',
          'movement_balance',
          'power_shot_power',
          'power_jumping',
          'power_stamina',
          'power_strength',
          'power_long_shots',
          'mentality_aggression',
          'mentality_interceptions',
          'mentality_positioning',
          'mentality_vision',
          'mentality_penalties',
          'mentality_composure',
          'defending_marking_awareness',
          'defending_standing_tackle',
          'defending_sliding_tackle',
          'goalkeeping_diving',
          'goalkeeping_handling',
          'goalkeeping_kicking',
          'goalkeeping_positioning',
          'goalkeeping_reflexes',
            ]].copy()

new_df.dtypes

# changing all the dtypes to float64
new_df = new_df.astype(np.float64)

#dropping all the null values
new_df = new_df.notna()
new_df.isnull().any()

"""## Splitting the data into training and Testing set"""

#create a test set and training set
from sklearn.model_selection import train_test_split
train_set, test_set= train_test_split(new_df, test_size= 0.2, random_state= 42)

y_train = train_set['overall'].copy()
x_train = train_set.drop(['overall'], axis=1)

# building the models
from sklearn.ensemble import RandomForestRegressor
forest =  RandomForestRegressor(random_state=42)
forest.fit(x_train, y_train)

#Evaluate the model on the testing set
from sklearn.metrics import mean_squared_error
forestPred = forest.predict(new_df)
forest_mse = mean_squared_error(labels, forestPred)
forest_rmse = np.sqrt(forest_mse)
forest_mse, forest_rmse

# Tune the model by adding the parameters to learn from
forest_new = RandomForestRegressor(random_state=42, max_features=1)
forest_new.fit(new_df, labels)

#checking the perfomance of the above model
newForestPred = forest_new.predict(new_df)
newForest_mse = mean_squared_error(labels, newForestPred)
newForest_rmse = np.sqrt(newForest_mse)
newForest_mse, newForest_rmse